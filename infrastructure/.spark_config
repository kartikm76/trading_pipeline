#!/bin/bash
# infrastructure/.spark_config - Single Source of Truth for EMR Tuning

# S3_BUCKET should be set by deploy_and_submit.sh based on ENV variable
S3_BUCKET=${S3_BUCKET:-trading-pipeline}

SUBMIT_PARAMS="--conf spark.app.is_bootstrap=${IS_BOOTSTRAP:-false} "
SUBMIT_PARAMS+="--conf spark.emr-serverless.driverEnv.PYSPARK_DRIVER_PYTHON=/usr/bin/python3.12 "
SUBMIT_PARAMS+="--conf spark.emr-serverless.driverEnv.PYSPARK_PYTHON=/usr/bin/python3.12 "
SUBMIT_PARAMS+="--conf spark.executorEnv.PYSPARK_PYTHON=/usr/bin/python3.12 "
SUBMIT_PARAMS+="--conf spark.emr-serverless.driverEnv.ENV=${ENV:-aws} "
SUBMIT_PARAMS+="--conf spark.executorEnv.ENV=${ENV:-aws} "
SUBMIT_PARAMS+="--py-files s3://$S3_BUCKET/artifacts/src.zip "
SUBMIT_PARAMS+="--files s3://$S3_BUCKET/artifacts/config.yaml "

# Resource Scaling
SUBMIT_PARAMS+="--conf spark.driver.memory=${DRIV_MEM} "
SUBMIT_PARAMS+="--conf spark.executor.memory=${EXEC_MEM} "
SUBMIT_PARAMS+="--conf spark.executor.instances=${MAX_EXECS} "
SUBMIT_PARAMS+="--conf spark.dynamicAllocation.enabled=false "
SUBMIT_PARAMS+="--conf spark.emr-serverless.executor.disk=100G "

# Catalog Config
SUBMIT_PARAMS+="--conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions "
SUBMIT_PARAMS+="--conf spark.sql.catalog.glue_catalog=org.apache.iceberg.spark.SparkCatalog "
SUBMIT_PARAMS+="--conf spark.sql.catalog.glue_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog "
SUBMIT_PARAMS+="--conf spark.sql.catalog.glue_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO "
SUBMIT_PARAMS+="--conf spark.sql.catalog.glue_catalog.warehouse=s3://$S3_BUCKET/iceberg-warehouse/ "